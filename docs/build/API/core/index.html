<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Core functions · NeuralEstimators.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralEstimators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralEstimators.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../motivation/">Motivation</a></li><li><span class="tocitem">Workflow</span><ul><li><a class="tocitem" href="../../workflow/overview/">Overview</a></li><li><a class="tocitem" href="../../workflow/simpleexample/">Simple example</a></li><li><a class="tocitem" href="../../workflow/morecomplicatedexample/">More complicated example</a></li><li><a class="tocitem" href="../../workflow/advancedusage/">Advanced usage</a></li></ul></li><li><span class="tocitem">API</span><ul><li class="is-active"><a class="tocitem" href>Core functions</a><ul class="internal"><li><a class="tocitem" href="#Parameters"><span>Parameters</span></a></li><li><a class="tocitem" href="#Simulation"><span>Simulation</span></a></li><li><a class="tocitem" href="#Deep-Set-representation"><span>Deep Set representation</span></a></li><li><a class="tocitem" href="#Training"><span>Training</span></a></li><li><a class="tocitem" href="#Estimation"><span>Estimation</span></a></li><li><a class="tocitem" href="#Bootstrapping"><span>Bootstrapping</span></a></li></ul></li><li><a class="tocitem" href="../simulation/">Simulation and density functions</a></li><li><a class="tocitem" href="../utility/">Utility functions</a></li><li><a class="tocitem" href="../">Index</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API</a></li><li class="is-active"><a href>Core functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Core functions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/main/docs/src/API/core.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Core-functions"><a class="docs-heading-anchor" href="#Core-functions">Core functions</a><a id="Core-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Core-functions" title="Permalink"></a></h1><h2 id="Parameters"><a class="docs-heading-anchor" href="#Parameters">Parameters</a><a id="Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Parameters" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.ParameterConfigurations" href="#NeuralEstimators.ParameterConfigurations"><code>NeuralEstimators.ParameterConfigurations</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">ParameterConfigurations</code></pre><p>An abstract supertype for storing parameters <code>θ</code> and any intermediate objects needed for data simulation with <code>simulate</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Parameters.jl#L1-L6">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.subsetparameters" href="#NeuralEstimators.subsetparameters"><code>NeuralEstimators.subsetparameters</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">subsetparameters(parameters::Parameters, indices) where {Parameters &lt;: ParameterConfigurations}</code></pre><p>Subset <code>parameters</code> using a collection of <code>indices</code>.</p><p>The default method assumes that each field of <code>parameters</code> is an array. If the last dimension of the array has size equal to the number of parameter configurations, K, then the array is subsetted over its last dimension using <code>indices</code>; otherwise, the field is returned unchanged. If this default does not cover your use case, define an appropriate subsetting method by overloading <code>subsetparameters</code> after running <code>import NeuralEstimators: subsetparameters</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Parameters.jl#L19-L29">source</a></section></article><h2 id="Simulation"><a class="docs-heading-anchor" href="#Simulation">Simulation</a><a id="Simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Simulation" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.simulate" href="#NeuralEstimators.simulate"><code>NeuralEstimators.simulate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">simulate(parameters::P, ξ, m::Integer, num_rep::Integer) where {P &lt;: ParameterConfigurations}</code></pre><p>Generic method that simulates <code>num_rep</code> sets of  sets of <code>m</code> independent replicates for each parameter configuration by calling <code>simulate(parameters, ξ, m)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Simulation.jl#L6-L11">source</a></section></article><h2 id="Deep-Set-representation"><a class="docs-heading-anchor" href="#Deep-Set-representation">Deep Set representation</a><a id="Deep-Set-representation-1"></a><a class="docs-heading-anchor-permalink" href="#Deep-Set-representation" title="Permalink"></a></h2><h3 id="Vanilla-Deep-Set"><a class="docs-heading-anchor" href="#Vanilla-Deep-Set">Vanilla Deep Set</a><a id="Vanilla-Deep-Set-1"></a><a class="docs-heading-anchor-permalink" href="#Vanilla-Deep-Set" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.DeepSet" href="#NeuralEstimators.DeepSet"><code>NeuralEstimators.DeepSet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DeepSet(ψ, ϕ, agg)</code></pre><p>Implementation of the Deep Set framework, where <code>ψ</code> and <code>ϕ</code> are neural networks (e.g., <code>Flux</code> networks) and <code>agg</code> is a symmetric function that pools data over the last dimension (the replicates/batch dimension) of an array.</p><p><code>DeepSet</code> objects are applied to <code>AbstractVectors</code> of <code>AbstractArrays</code>, where each array is associated with one parameter vector.</p><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">n = 10 # observations in each realisation
p = 5  # number of parameters in the statistical model
w = 32 # width of each layer
ψ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ = Chain(Dense(w, w, relu), Dense(w, p));
agg(X) = sum(X, dims = ndims(X))
θ̂  = DeepSet(ψ, ϕ, agg)

# A single set of m=3 realisations:
Z = [rand(n, 1, 3)];
θ̂ (Z)

# Two sets each containing m=3 realisations:
Z = [rand(n, 1, m) for m ∈ (3, 3)];
θ̂ (Z)

# Two sets respectivaly containing m=3 and m=4 realisations:
Z = [rand(n, 1, m) for m ∈ (3, 4)];
θ̂ (Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/DeepSet.jl#L25-L57">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.DeepSet-Tuple{Any, Any}" href="#NeuralEstimators.DeepSet-Tuple{Any, Any}"><code>NeuralEstimators.DeepSet</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">DeepSet(ψ, ϕ; aggregation::String = &quot;mean&quot;)</code></pre><p>Convenient constructor for a <code>DeepSet</code> object with <code>agg</code> equal to the <code>&quot;mean&quot;</code>, <code>&quot;sum&quot;</code>, or <code>&quot;logsumexp&quot;</code> function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/DeepSet.jl#L66-L71">source</a></section></article><h3 id="Deep-Set-with-expert-summary-statistics"><a class="docs-heading-anchor" href="#Deep-Set-with-expert-summary-statistics">Deep Set with expert summary statistics</a><a id="Deep-Set-with-expert-summary-statistics-1"></a><a class="docs-heading-anchor-permalink" href="#Deep-Set-with-expert-summary-statistics" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.DeepSetExpert" href="#NeuralEstimators.DeepSetExpert"><code>NeuralEstimators.DeepSetExpert</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DeepSetExpert(ψ, ϕ, S, agg)</code></pre><p>Implementation of the Deep Set framework with <code>ψ</code> and <code>ϕ</code> neural networks, <code>agg</code> a symmetric function that pools data over the last dimension of an array, and <code>S</code> a vector of real-valued functions that serve as expert summary statistics.</p><p>The dimension of the domain of <code>ϕ</code> should be qₜ + qₛ, where qₜ is the range of <code>ϕ</code> and qₛ is the dimension of <code>S</code>, that is, <code>length(S)</code>. <code>DeepSetExpert</code> objects are applied to <code>AbstractVectors</code> of <code>AbstractArrays</code>, where each array is associated with one parameter vector. The functions <code>ψ</code> and <code>S</code> both act on these arrays individually (i.e., they are broadcasted over the <code>AbstractVector</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/DeepSetExpert.jl#L21-L32">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.DeepSetExpert-Tuple{DeepSet, Any, Any}" href="#NeuralEstimators.DeepSetExpert-Tuple{DeepSet, Any, Any}"><code>NeuralEstimators.DeepSetExpert</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">DeepSetExpert(deepset::DeepSet, ϕ, S)</code></pre><p><code>DeepSetExpert</code> constructor with the aggregation function <code>agg</code> and inner neural network <code>ψ</code> inherited from <code>deepset</code>.</p><p>Note that we cannot inherit the outer network, <code>ϕ</code>, since <code>DeepSetExpert</code> objects require the dimension of the domain of <code>ϕ</code> to be qₜ + qₛ.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/DeepSetExpert.jl#L50-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.DeepSetExpert-Tuple{Any, Any, Any}" href="#NeuralEstimators.DeepSetExpert-Tuple{Any, Any, Any}"><code>NeuralEstimators.DeepSetExpert</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">DeepSetExpert(ψ, ϕ, S; aggregation::String = &quot;mean&quot;)</code></pre><p><code>DeepSetExpert</code> constructor with <code>agg</code> equal to the <code>&quot;mean&quot;</code>, <code>&quot;sum&quot;</code>, or <code>&quot;logsumexp&quot;</code> function.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/DeepSetExpert.jl#L41-L46">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.samplesize" href="#NeuralEstimators.samplesize"><code>NeuralEstimators.samplesize</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">samplesize(Z::A) where {A &lt;: AbstractArray{T, N}} where {T, N}</code></pre><p>Computes the sample size m for a set of independent realisations <code>Z</code>, useful as an expert summary statistic in <code>DeepSetExpert</code> objects.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/DeepSetExpert.jl#L2-L7">source</a></section></article><h3 id="Piecewise-Deep-Set-neural-estimators"><a class="docs-heading-anchor" href="#Piecewise-Deep-Set-neural-estimators">Piecewise Deep Set neural estimators</a><a id="Piecewise-Deep-Set-neural-estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Piecewise-Deep-Set-neural-estimators" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.DeepSetPiecewise" href="#NeuralEstimators.DeepSetPiecewise"><code>NeuralEstimators.DeepSetPiecewise</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">DeepSetPiecewise(estimators, m_cutoffs)</code></pre><p>Given an arbitrary number of <code>estimators</code>, creates a piecewise neural estimator based on the sample size cut offs, <code>m_cutoffs</code>, which should contain one element fewer than the number of estimators.</p><p><strong>Examples</strong></p><p>Suppose that we have two neural estimators, <code>θ̂₁</code> and <code>θ̂₂</code>, taking the following arbitrary forms:</p><pre><code class="nohighlight hljs">n = 10
p = 5
w = 32

ψ₁ = Chain(Dense(n, w, relu), Dense(w, w, relu));
ϕ₁ = Chain(Dense(w, w, relu), Dense(w, p));
θ̂₁ = DeepSet(ψ₁, ϕ₁)

ψ₂ = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu));
ϕ₂ = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, p));
θ̂₂ = DeepSet(ψ₂, ϕ₂)</code></pre><p>Further suppose that we&#39;ve trained <code>θ̂₁</code> for small sample sizes (e.g., m ≤ 30) and <code>θ̂₂</code> for moderate-to-large sample sizes (e.g., m &gt; 30). Then we construct a piecewise Deep Set object with a cut-off sample size of 30 which dispatches θ̂₁ if m ≤ 30 and θ̂₂ if m &gt; 30:</p><pre><code class="nohighlight hljs">θ̂ = DeepSetPiecewise((θ̂₁, θ̂₂), (30,))
Z = [rand(Float32, n, 1, m) for m ∈ (10, 50)]
θ̂(Z)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/DeepSetPiecewise.jl#L14-L49">source</a></section></article><h2 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h2><p>There are two training methods. For both methods, the validation parameters and validation data are held fixed so that the validation risk is interpretable. There are a number of practical considerations to keep in mind: In particular, see <a href="../../workflow/advancedusage/#Balancing-time-and-memory-complexity-during-training">Balancing time and memory complexity during training</a>.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.train" href="#NeuralEstimators.train"><code>NeuralEstimators.train</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">train(θ̂, ξ, P; &lt;keyword args&gt;) where {P &lt;: ParameterConfigurations}</code></pre><p>Train the neural estimator <code>θ̂</code> by providing the invariant model information <code>ξ</code> needed for the constructor <code>P</code> to automatically sample the sets of training and validation parameters.</p><p><strong>Keyword arguments common to both <code>train</code> methods:</strong></p><ul><li><code>m</code>: sample sizes (either an <code>Integer</code> or a collection of <code>Integers</code>).</li><li><code>batchsize::Integer = 32</code></li><li><code>epochs::Integer = 100</code>: the maximum number of epochs used during training.</li><li><code>epochs_per_Z_refresh::Integer = 1</code>: how often to refresh the training data.</li><li><code>loss = mae</code>: the loss function, which should return an average loss when applied to multiple replicates.</li><li><code>optimiser = ADAM(1e-4)</code></li><li><code>savepath::String = &quot;runs/&quot;</code>: path to save the trained <code>θ̂</code> and other information; if savepath is an empty string (i.e., <code>&quot;&quot;</code>), nothing is saved.</li><li><code>simulate_just_in_time::Bool = false</code>: should we do &quot;just-in-time&quot; data simulation, which improves memory complexity at the cost of time complexity?</li><li><code>stopping_epochs::Integer = 10</code>: cease training if the risk doesn&#39;t improve in <code>stopping_epochs</code> epochs.</li><li><code>use_gpu::Bool = true</code></li><li><code>verbose::Bool = true</code></li></ul><p><strong>Simulator keyword arguments only:</strong></p><ul><li><code>K::Integer = 10_000</code>: the number of parameters in the training set; the size of the validation set is <code>K ÷ 5</code>.</li><li><code>epochs_per_θ_refresh::Integer = 1</code>: how often to refresh the training parameters; this must be a multiple of <code>epochs_per_Z_refresh</code>.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Train.jl#L15-L28">source</a></section><section><div><pre><code class="nohighlight hljs">train(θ̂, ξ, θ_train::P, θ_val::P; &lt;keyword args&gt;) where {P &lt;: ParameterConfigurations}</code></pre><p>Train the neural estimator <code>θ̂</code> by providing the training and validation parameter sets explicitly as <code>θ_train</code> and <code>θ_val</code>, which are both held fixed during training, as well as the invariant model information <code>ξ</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Train.jl#L133-L139">source</a></section><section><div><pre><code class="nohighlight hljs">train(θ̂, θ_train::P, θ_val::P, Z_train::T, Z_val::T; &lt;keyword args&gt;) where {T, P &lt;: ParameterConfigurations}</code></pre><p>Train the neural estimator <code>θ̂</code> by providing the training and validation parameter sets, <code>θ_train</code> and <code>θ_val</code>, and the training and validation data sets, <code>Z_train</code> and <code>Z_val</code>, all of which are held fixed during training.</p><p>The sample size argument <code>m</code> is inferred from <code>Z_val</code>. The training data <code>Z_train</code> can contain <code>M</code> replicates, where <code>M</code> is a multiple of <code>m</code>; the training data will then be recycled to imitate on-the-fly simulation. For example, if <code>M = 50</code> and <code>m = 10</code>, epoch 1 uses the first 10 replicates, epoch 2 uses the second 10 replicates, and so on, until epoch 6 again uses the first 10 replicates.</p><p>Note that the elements of <code>Z_train</code> and <code>Z_val</code> should be equally replicated; that is, the size of the last dimension in each array in <code>Z_train</code> should be constant, and similarly for <code>Z_val</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Train.jl#L265-L281">source</a></section></article><h2 id="Estimation"><a class="docs-heading-anchor" href="#Estimation">Estimation</a><a id="Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Estimation" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.estimate" href="#NeuralEstimators.estimate"><code>NeuralEstimators.estimate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">estimate(estimators, ξ, parameters::P; &lt;keyword args&gt;) where {P &lt;: ParameterConfigurations}</code></pre><p>Using a collection of <code>estimators</code>, compute estimates from data simulated from a set of <code>parameters</code> with invariant information <code>ξ</code>.</p><p>Note that <code>estimate()</code> requires the user to have defined a method <code>simulate(parameters, ξ, m::Integer)</code>.</p><p><strong>Keyword arguments</strong></p><ul><li><code>m::Vector{Integer}</code>: sample sizes to estimate from.</li><li><code>estimator_names::Vector{String}</code>: names of the estimators (sensible default values provided).</li><li><code>parameter_names::Vector{String}</code>: names of the parameters (sensible default values provided).</li><li><code>num_rep::Integer = 1</code>: the number of times to replicate each parameter in <code>parameters</code>.</li><li><code>save::Vector{String}</code>: by default, no objects are saved; however, if <code>save</code> is provided, four <code>DataFrames</code> respectively containing the true parameters <code>θ</code>, estimates <code>θ̂</code>, runtimes, and merged <code>θ</code> and <code>θ̂</code> will be saved in the directory <code>save[1]</code> with file <em>names</em> (not extensions) suffixed by <code>save[2]</code>.</li><li><code>use_ξ = false</code>: a <code>Bool</code> or a collection of <code>Bool</code> objects with length equal to the number of estimators. Specifies whether or not the estimator uses the invariant model information, <code>ξ</code>: If it does, the estimator will be applied as <code>estimator(Z, ξ)</code>.</li><li><code>use_gpu = true</code>: a <code>Bool</code> or a collection of <code>Bool</code> objects with length equal to the number of estimators.</li><li><code>verbose::Bool = true</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Estimate.jl#L1-L18">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.Estimates" href="#NeuralEstimators.Estimates"><code>NeuralEstimators.Estimates</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Estimates(θ, θ̂, runtime)</code></pre><p>A set of true parameters <code>θ</code>, corresponding estimates <code>θ̂</code>, and the <code>runtime</code> to obtain <code>θ̂</code>, as returned by a call to <code>estimate</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Estimate.jl#L113-L118">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Base.merge-Tuple{Estimates}" href="#Base.merge-Tuple{Estimates}"><code>Base.merge</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">merge(estimates::Estimates)</code></pre><p>Merge <code>estimates</code> into a single long-form <code>DataFrame</code> containing the true parameters and the corresponding estimates.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Estimate.jl#L125-L130">source</a></section></article><h2 id="Bootstrapping"><a class="docs-heading-anchor" href="#Bootstrapping">Bootstrapping</a><a id="Bootstrapping-1"></a><a class="docs-heading-anchor-permalink" href="#Bootstrapping" title="Permalink"></a></h2><p>Note that all bootstrapping functions are currently implemented for a single parameter configuration only.</p><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.parametricbootstrap" href="#NeuralEstimators.parametricbootstrap"><code>NeuralEstimators.parametricbootstrap</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">parametricbootstrap(θ̂, parameters::P, ξ, m::Integer; B::Integer = 100, use_gpu::Bool = true) where {P &lt;: ParameterConfigurations}</code></pre><p>Returns <code>B</code> parameteric bootstrap samples of an estimator <code>θ̂</code> as a p × <code>B</code> matrix, where p is the number of parameters in the statistical model, based on data sets of size <code>m</code> simulated using the invariant model information <code>ξ</code> and parameter configurations, <code>parameters</code>.</p><p>This function requires the user to have defined a method <code>simulate(parameters::P, ξ, m::Integer</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Bootstrap.jl#L5-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="NeuralEstimators.nonparametricbootstrap" href="#NeuralEstimators.nonparametricbootstrap"><code>NeuralEstimators.nonparametricbootstrap</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">nonparametricbootstrap(θ̂, Z::AbstractArray{T, N}; B::Integer = 100, use_gpu::Bool = true)
nonparametricbootstrap(θ̂, Z::AbstractArray{T, N}, blocks; B::Integer = 100, use_gpu::Bool = true)</code></pre><p>Returns <code>B</code> non-parametric bootstrap samples of an estimator <code>θ̂</code> as a p × <code>B</code> matrix, where p is the number of parameters in the statistical model.</p><p>The argument <code>blocks</code> caters for block bootstrapping, and should be an integer vector specifying the block for each replicate. For example, if we have 5 replicates with the first two replicates corresponding to block 1 and the remaining replicates corresponding to block 2, then <code>blocks</code> should be [1, 1, 2, 2, 2]. The resampling algorithm tries to produce resampled data sets of a similar size to the original data, but this can only be achieved exactly if the blocks are the same length.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/msainsburydale/NeuralEstimators.jl/blob/8d5d1ed4bf1c1f51ec099710c46922d4a588f110/src/Bootstrap.jl#L28-L42">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../workflow/advancedusage/">« Advanced usage</a><a class="docs-footer-nextpage" href="../simulation/">Simulation and density functions »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.20 on <span class="colophon-date" title="Friday 15 July 2022 06:06">Friday 15 July 2022</span>. Using Julia version 1.7.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
