var documenterSearchIndex = {"docs":
[{"location":"workflow/morecomplicatedexample/#More-complicated-example","page":"More complicated example","title":"More complicated example","text":"","category":"section"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"In this example, we'll consider a standard spatial model, the linear Gaussian-Gaussian model,","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"Z_i = Y(mathbfs_i) + epsilon_i quad  i = 1 dots n","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"where mathbfZ equiv (Z_1 dots Z_n)^top are data observed at locations mathbfs_1 dots mathbfs_n subset mathcalD, Y(cdot) is a spatially-correlated mean-zero Gaussian process, and epsilon_i sim rmN(0 sigma^2_epsilon) is Gaussian white noise with sigma^2_epsilon the measurement-error variance parameter. An important component of the model is the covariance function, C(mathbfs mathbfu) equiv rmcov(Y(mathbfs) Y(mathbfu)), for mathbfs mathbfu in mathcalD, which is the primary mechanism for capturing spatial dependence. Here, we use the popular isotropic Mat√©rn covariance function,","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":" C(mathbfh) = sigma^2 frac2^1 - nuGamma(nu) left(fracmathbfhrhoright) K_nu left(fracmathbfhrhoright)","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"where sigma is the marginal variance parameter, Gamma(cdot) is the gamma function, K_nu(cdot) is the Bessel function of the second kind of order nu, and rho  0 and nu  0 are the range and smoothness parameters, respectively. We follow the common practice decision to fix sigma to 1, and we also fix nu = 1 for simplicity. This leaves two unknown parameters that need to be estimated: mathbftheta equiv (sigma_epsilon rho)^top.","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"The invariant model objects in this example are the prior distribution, the spatial locations, and the distance matrix. We'll assume prior independence between the parameters with log-uniform margins. We'll take our spatial domain of interest, mathcalD, to be 0 9 times 0 9, and we'll simulate data on a regular grid with neighbours in each dimension separated by 1 unit.","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"using NeuralEstimators\nusing Distributions\nŒ© = (\n \tœÉ‚Çë = LogUniform(0.05, 0.5),\n\tœÅ  = LogUniform(2, 6)\n)\nS = expandgrid(1:9, 1:9)\nS = Float32.(S)\nD = pairwise(Euclidean(), S, S, dims = 1)\nŒæ = (Œ© = Œ©, S = S, D = D)","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"Next, we define a subtype of ParameterConfigurations. For the current model, Cholesky factors of covariance matrices are a key intermediate object needed for data simulation, so they are included in addition to the compulsory field Œ∏.","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"struct Parameters <: ParameterConfigurations\n \tŒ∏\n\tchols\nend","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"We then define a Parameters constructor, returning a Parameters object with K parameters and corresponding Choleksy factors: Below, we employ the function maternchols(D, œÅ, ŒΩ).","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"function Parameters(Œæ, K::Integer)\n\n Œ©  = Œæ.Œ©\n œÉ‚Çë = rand(Œ©.œÉ‚Çë, 1, K)\n œÅ  = rand(Œ©.œÅ, 1, K)\n Œ∏  = vcat(œÉ‚Çë, œÅ)\n\n chols = maternchols(Œæ.D, œÅ, 1)\n\n Parameters(Œæ, chols)\nend","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"Next, we implicitly define the statistical model by overloading simulate:","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"import NeuralEstimators: simulate\nfunction simulate(parameters::Parameters, Œæ, m::Integer)\n\n\tL = parameters.chols\n\tn = size(L, 1)\n\tK = size(parameters, 2)\n\n\t# For the kth parameter configuration, extract the corresponding Cholesky\n\t# factor, initialise an array to store the m replicates, and simulate from\n\t# the model:\n\tZ = map(1:K) do k\n\t\tL‚Çñ = L[:, :, k]\n\t\tz = similar(L‚Çñ, n, m)\n\t\tfor i ‚àà 1:m\n\t\t\tz[:, i] = L‚Çñ *  randn(T, n) + œÉ‚Çë * randn(T, n)\n\t\tend\n\t\treturn z\n\tend\n\n\t# Convert fields to a square domain and add a singleton dimension for\n\t# compatibility with Flux:\n\t@assert isqrt(n) == sqrt(n)\n\tZ = reshape.(Z, isqrt(n), isqrt(n), 1, :)  \n\n\treturn Z\nend","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"We then choose an architecture for modelling œà(‚ãÖ) and œï(‚ãÖ) in the Deep Set framework, and initialise the neural estimator as a DeepSet object. Note that functions for defining architectures based on the number of parameters in the statistical model, p, can be useful when working with several models.","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"function architecture(p)\n\n œà = Chain(\n\t Conv((10, 10), 1 => 32,  relu),\n\t Conv((5, 5),  32 => 64,  relu),\n\t Conv((3, 3),  64 => 128, relu),\n\t Flux.flatten,\n\t Dense(128, 256, relu)\n\t )\n\n œï = Chain(\n\t Dense(256, 128, relu),\n\t Dense(128, 64, relu),\n\t Dense(64, 32, relu),\n\t Dense(32, p),\n\t x -> exp.(x)\n )\n\n return œà, œï\nend\n\np = 2\nœà, œï = architecture(p)\nŒ∏ÃÇ = DeepSet(œà, œï)","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"Next, we train the neural estimator using train. For this model, generating Parameters is somewhat expensive due to computation of Choleksy factors. Hence, it can be computationally advantageous to keep the training and validation parameter sets fixed during training, and this is achieved by providing these sets to train:","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"Œ∏_train = Parameters(Œæ, 5000)\nŒ∏_val   = Parameters(Œæ, 500)\nŒ∏ÃÇ = train(Œ∏ÃÇ, Œæ, Parameters, m = 10)","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"Note that the above set sizes may be too low to obtain an optimal estimator and, with the current implementation, we are somewhat restricted to using modest set sizes: For a general way to cope with this challenge, see Sharing intermediate objects between parameter configurations.","category":"page"},{"location":"workflow/morecomplicatedexample/","page":"More complicated example","title":"More complicated example","text":"Irrespective of the model, the functions estimate and merge are used as described previously.","category":"page"},{"location":"API/simulation/#Data-simulation","page":"Data simulation","title":"Data simulation","text":"","category":"section"},{"location":"API/simulation/#Model-simulators","page":"Data simulation","title":"Model simulators","text":"","category":"section"},{"location":"API/simulation/","page":"Data simulation","title":"Data simulation","text":"simulategaussianprocess\n\nsimulateschlather\n\nsimulateconditionalextremes","category":"page"},{"location":"API/simulation/#NeuralEstimators.simulategaussianprocess","page":"Data simulation","title":"NeuralEstimators.simulategaussianprocess","text":"simulategaussianprocess(L::AbstractArray{T, 2}, œÉ::T, m::Integer)\nsimulategaussianprocess(L::AbstractArray{T, 2})\n\nSimulates m realisations from a Gau(0, ùö∫ + œÉ¬≤ùêà) distribution, where ùö∫ ‚â° LL'.\n\nIf œÉ and m are not provided, a single field without nugget variance is returned.\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.simulateschlather","page":"Data simulation","title":"NeuralEstimators.simulateschlather","text":"simulateschlather(L::AbstractArray{T, 2}; C = 3.5)\nsimulateschlather(L::AbstractArray{T, 2}, m::Integer; C = 3.5)\n\nSimulates from Schlather's max-stable model. Based on Algorithm 1.2.2 of Dey DK, Yan J (2016). Extreme value modeling and risk analysis: methods and applications. CRC Press, Boca Raton, Florida.\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.simulateconditionalextremes","page":"Data simulation","title":"NeuralEstimators.simulateconditionalextremes","text":"simulateconditionalextremes(Œ∏, L::AbstractArray{T, 2}, S, s‚ÇÄ, u)\nsimulateconditionalextremes(Œ∏, L::AbstractArray{T, 2}, S, s‚ÇÄ, u, m::Integer)\n\nSimulates from the spatial conditional extremes model.\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#Intermediate-objects","page":"Data simulation","title":"Intermediate objects","text":"","category":"section"},{"location":"API/simulation/","page":"Data simulation","title":"Data simulation","text":"matern\n\nmaternchols\n\nobjectindices\n\nincgamma\n\nf‚Çõ","category":"page"},{"location":"API/simulation/#NeuralEstimators.matern","page":"Data simulation","title":"NeuralEstimators.matern","text":"matern(h, œÅ, ŒΩ, œÉ¬≤ = 1)\n\nFor two points separated by h units, compute the Mat√©rn covariance function with range œÅ, smoothness ŒΩ, and marginal variance œÉ¬≤.\n\nWe use the parametrisation C(mathbfh) = sigma^2 frac2^1 - nuGamma(nu) left(fracmathbfhrhoright) K_nu left(fracmathbfhrhoright), where Gamma(cdot) is the gamma function, and K_nu(cdot) is the modified Bessel function of the second kind of order nu. This parameterisation is the same as used by the R package fields, but differs to the parametrisation given by Wikipedia.\n\nNote that the Julia functions for Gamma(cdot) and K_nu(cdot), respectively gamma() and besselk(), do not work on the GPU and, hence, nor does matern().\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.maternchols","page":"Data simulation","title":"NeuralEstimators.maternchols","text":"maternchols(D, œÅ, ŒΩ)\n\nGiven a distance matrix D, computes the covariance matrix Œ£ under the Mat√©rn covariance function with range œÅ and smoothness ŒΩ, and return the Cholesky factor of this matrix.\n\nProviding vectors for œÅ and ŒΩ will yield a three-dimensional array of Cholesky factors.\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.objectindices","page":"Data simulation","title":"NeuralEstimators.objectindices","text":"objectindices(objects, Œ∏::AbstractMatrix{T}) where T\n\nReturns a vector of indices giving element of objects associated with each parameter configuration in Œ∏.\n\nThe number of parameter configurations, K = size(Œ∏, 2), must be a multiple of the number of objects, N = size(objects)[end]. Further, repeated parameters used to generate objects must be stored in Œ∏ after using the inner keyword argument of repeat() (see example below).\n\nExamples\n\nK = 6\nN = 3\nœÉ‚Çë = rand(K)\nœÅ = rand(N)\nŒΩ = rand(N)\nS = expandgrid(1:9, 1:9)\nD = pairwise(Euclidean(), S, S, dims = 1)\nL = maternchols(D, œÅ, ŒΩ)\nœÅ = repeat(œÅ, inner = K √∑ N)\nŒΩ = repeat(ŒΩ, inner = K √∑ N)\nŒ∏ = hcat(œÉ‚Çë, œÅ, ŒΩ)'\nobjectindices(L, Œ∏)\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.incgamma","page":"Data simulation","title":"NeuralEstimators.incgamma","text":"incgamma(a::T, x::T; upper::Bool, reg::Bool) where {T <: AbstractFloat}\n\nFor positive parameter a and positive integration limit x, computes the incomplete gamma function, as described by the Wikipedia article.\n\nKeyword arguments:\n\nupper::Bool: if true, the upper incomplete gamma function is returned; otherwise, the lower version is returned.\nreg::Bool: if true, the regularized incomplete gamma function is returned; otherwise, the unregularized version is returned.\n\n\n\n\n\n","category":"function"},{"location":"API/simulation/#NeuralEstimators.f‚Çõ","page":"Data simulation","title":"NeuralEstimators.f‚Çõ","text":"f‚Çõ(x, Œº, œÑ, Œ¥)\nF‚Çõ(q, Œº, œÑ, Œ¥)\nF‚Çõ‚Åª¬π(p, Œº, œÑ, Œ¥)\n\nThe density, distribution, and quantile functions Subbotin (delta-Laplace) distribution with location parameter Œº, scale parameter œÑ, and shape parameter Œ¥:\n\n f_S(y mu tau delta) = fracdelta2tau Gamma(1delta) expleft(-leftfracy - mutauright^deltaright)\n F_S(y mu tau delta) = frac12 + textrmsign(y - mu) frac12 Gamma(1delta) gammaleft(1delta leftfracy - mutauright^deltaright)\n F_S^-1(p mu tau delta) = textsign(p - 05)G^-1left(2p - 05 frac1delta frac1(ktau)^deltaright)^1delta + mu\n\nwith gamma(cdot) and G^-1(cdot) the unnormalised incomplete lower gamma function and quantile function of the Gamma distribution, respectively.\n\nExamples\n\np = [0.025, 0.05, 0.5, 0.9, 0.95, 0.975]\n\n# Standard Gaussian:\nŒº = 0.0; œÑ = sqrt(2); Œ¥ = 2.0\nF‚Çõ‚Åª¬π.(p, Œº, œÑ, Œ¥)\n\n# Standard Laplace:\nŒº = 0.0; œÑ = 1.0; Œ¥ = 1.0\nF‚Çõ‚Åª¬π.(p, Œº, œÑ, Œ¥)\n\n\n\n\n\n","category":"function"},{"location":"API/#Index","page":"Index","title":"Index","text":"","category":"section"},{"location":"API/","page":"Index","title":"Index","text":"","category":"page"},{"location":"related/","page":"-","title":"-","text":"You may also be interested in the Julia packages Flux (the deep learning framework this package is built upon), Turing (for general-purpose probabilistic programming), and Mill (for generalised multiple-instance learning models). ","category":"page"},{"location":"workflow/advancedusage/#Advanced-usage","page":"Advanced usage","title":"Advanced usage","text":"","category":"section"},{"location":"workflow/advancedusage/#Loading-previously-saved-neural-estimators","page":"Advanced usage","title":"Loading previously saved neural estimators","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"As training is by far the most computationally demanding part of the workflow, one typically trains an estimator and then saves it for later use. More specifically, one usually saves the parameters of the neural estimator (e.g., the weights and biases of the neural networks); then, to load the neural estimator a later time, one initialises an estimator with the same architecture used during training, and then loads the saved parameters into this estimator.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"train automatically saves the neural estimator's parameters; to load them, one may use the following code, or similar:","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"using NeuralEstimators\nusing Flux\nœà, œï = architecture(p)\nŒ∏ÃÇ = DeepSet(œà, œï)\nFlux.loadparams!(Œ∏ÃÇ, loadbestweights(path))","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Above, architecture(p) returns the architecture used during training, where p is the number of parameters in the statistical model; Flux.loadparams! loads the parameters of the best neural estimator saved in path, as determined loadbestweights.","category":"page"},{"location":"workflow/advancedusage/#Computational-considerations","page":"Advanced usage","title":"Computational considerations","text":"","category":"section"},{"location":"workflow/advancedusage/#Balancing-time-and-memory-complexity-during-training","page":"Advanced usage","title":"Balancing time and memory complexity during training","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"\"On-the-fly\" simulation refers to simulating new values for the parameters, Œ∏, and/or the data, Z, continuously during training. \"Just-in-time\" simulation refers to simulating small batches of parameters and data, training the neural estimator with this small batch, and then removing the batch from memory.   ","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"There are three variants of on-the-fly and just-in-time simulation, each with advantages and disadvantages.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Resampling Œ∏ and Z every epoch. This approach is the most theoretically justified and has the best memory complexity, since both Œ∏ and Z can be simulated just-in-time, but it has the worst time complexity.\nResampling Œ∏ every x epochs, resampling Z every epoch. This approach can reduce time complexity if generating Œ∏ (or intermediate objects thereof) dominates the computational cost. Further, memory complexity may be kept low since Z can still be simulated just-in-time.\nResampling Œ∏ every x epochs, resampling Z every y epochs, where x is a multiple of y. This approach minimises time complexity but has the largest memory complexity, since both Œ∏ and Z must be stored in full. Note that fixing Œ∏ and Z (i.e., setting y = ‚àû) often leads to worse out-of-sample performance and, hence, is generally discouraged.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"The keyword arguments epochs_per_Œ∏_refresh and epochs_per_Z_refresh in train() are intended to cater for these simulation variants.","category":"page"},{"location":"workflow/advancedusage/#Sharing-intermediate-objects-between-parameter-configurations","page":"Advanced usage","title":"Sharing intermediate objects between parameter configurations","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"For some models, computationally expensive intermediate objects, such as Cholesky factors when working with Gaussian process models, can be shared between multiple parameter configurations (Gerber and Nychka, 2021), and this can significantly reduce the training time and alleviate memory pressure.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Recall that in the More complicated example considered previously, we computed the Cholesky factor for each parameter configuration. However, for that model, the Cholesky factor depends only on rho and, hence, we can modify our design to exploit this fact and significantly reduce the computational burden in generating ParameterConfigurations objects. The following is one such approach.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"The key to our approach is the inclusion of an additional field in Parameters that gives index of the Cholesky factor associated with each parameter configuration:","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"struct Parameters <: ParameterConfigurations\n\tŒ∏\n\tchols\n\tchol_index\nend","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Then, we adapt our Parameters constructor so that, instead of sampling K parameter pairs independently, we sample K √∑ N values of œÅ, and then repeat these parameters so that the final parameter vector has length K. The advantage of this approach is clear, in that we need only compute K √∑ N Cholesky factors.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"function Parameters(Œæ, K::Integer; N = 10)\n\n\t@assert K % N == 0\n\n\tŒ© = Œæ.Œ©\n\n\tœÉ = rand(Œ©.œÉ, N)\n\tœÅ = rand(Œ©.œÅ, K √∑ N)\n\n\tchols = maternchols(Œæ.D, œÅ, 1)\n\n\t# Construct Œ∏ such that œÉ runs faster than œÅ\n\tœÉ = repeat(œÉ, outer = K √∑ N)\n\tœÅ = repeat(œÅ, inner = N)\n\tŒ∏ = hcat(œÉ, œÅ)'\n\n\tParameters(Œ∏, chols, objectindices(chols, Œ∏))\nend","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"The above constructor makes use of the the convenience function objectindices, which computes the index of the Cholesky factor associated with each parameter configuration (and with intermediate objects more generally).","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Note that the default subsetting method for ParameterConfigurations objects automatically handles cases like this; in some applications, however, it may be necessary to define an appropriate subsetting method by overloading subsetparameters.","category":"page"},{"location":"workflow/advancedusage/#Variable-sample-sizes","page":"Advanced usage","title":"Variable sample sizes","text":"","category":"section"},{"location":"workflow/advancedusage/#Training-with-a-variable-sample-size","page":"Advanced usage","title":"Training with a variable sample size","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"We often wish to apply a neural estimator to range of sample sizes m, that is, we would like the estimator to be able to draw strength from a variable number of independent replicates. To this end, it is typically helpful to also train the neural estimator with variable m, and this does not materially alter the workflow, except that one also needs to define a method of simulate for variable m.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Below we define data simulation for a range of sample sizes (i.e., a range of integers) under a uniform prior for M, the random variable corresponding to sample size.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"function simulate(parameters::Parameters, Œæ, m::R) where {R <: AbstractRange{I}} where I <: Integer\n\n\t# Sample K sample sizes\n\tmÃÉ = rand(m, K)\n\n\t# Pseudocode demonstrating the basic workflow\n\tZ = [<simulate mÃÉ[k] fields> for k ‚àà 1:K]\n\n\treturn Z\nend","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Then, setting the argument m in train to be an integer range will train the neural estimator with the given variable sample sizes.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"It's convenient to be able to switch back and forth between training with a fixed and variable sample size as we see fit, and this can be achieved by trivially defining a method for m::Integer (and note that such a method is needed for other parts of the workflow):","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"simulate(parameters::Parameters, Œæ, m::Integer) = simulate(parameters, Œæ, range(m, m))","category":"page"},{"location":"workflow/advancedusage/#Piecewise-neural-estimators","page":"Advanced usage","title":"Piecewise neural estimators","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"See DeepSetPiecewise.","category":"page"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"hatmathbftheta(mathcalZ)\n=\nbegincases\nhatmathbftheta_1(mathcalZ)  mathcalZ leq m_1\nhatmathbftheta_2(mathcalZ)  m_1  mathcalZ leq m_2\nquad vdots \nhatmathbftheta_l(mathcalZ)  mathcalZ  m_l-1\nendcases","category":"page"},{"location":"workflow/advancedusage/#Combining-neural-and-expert-summary-statistics","page":"Advanced usage","title":"Combining neural and expert summary statistics","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"See DeepSetExpert.","category":"page"},{"location":"workflow/advancedusage/#Bootstrapping","page":"Advanced usage","title":"Bootstrapping","text":"","category":"section"},{"location":"workflow/advancedusage/","page":"Advanced usage","title":"Advanced usage","text":"Bootstrapping is a powerful technique for estimating the distribution of an estimator and, hence, facilitating uncertainty quantification. Bootstrap methods are considered to be accurate but often too computationally expensive for traditional likelihood-based estimators, but are well suited to fast neural estimators. We implement bootstrapping with  parametricbootstrap and nonparametricbootstrap, with the latter also catering for so-called block bootstrapping.","category":"page"},{"location":"workflow/overview/#Workflow-overview","page":"Overview","title":"Workflow overview","text":"","category":"section"},{"location":"workflow/overview/","page":"Overview","title":"Overview","text":"To develop a neural estimator with NeuralEstimators.jl,","category":"page"},{"location":"workflow/overview/","page":"Overview","title":"Overview","text":"Create an object Œæ containing invariant model information, that is, model information that does not depend on the parameters and hence stays constant during training (e.g, the prior distribution of the parameters, spatial locations, distance matrices, etc.).\nDefine a subtype of ParameterConfigurations, say, Parameters (the name is arbitrary), containing a compulsory field Œ∏ storing K parameter vectors as a p √ó K matrix, with p the dimension of Œ∏, as well as any other intermediate objects associated with the parameters (e.g., Cholesky factors) that are needed for data simulation.\nDefine a Parameters constructor Parameters(Œæ, K::Integer), which draws K parameters from the prior.\nImplicitly define the statistical model by overloading the function simulate.\nInitialise neural networks œà and œï, and a DeepSet object Œ∏ÃÇ = DeepSet(œà, œï).\nTrain Œ∏ÃÇ using train under an arbitrary loss function.\nTest Œ∏ÃÇ using estimate.\nApply Œ∏ÃÇ to a real data set, using parametricbootstrap or nonparametricbootstrap to estimate the distribution of the estimator and, hence, facilitate uncertainty quantification.","category":"page"},{"location":"workflow/overview/","page":"Overview","title":"Overview","text":"For clarity, see a Simple example and a More complicated example. Once familiar with the basic workflow, see Advanced usage for some important practical considerations and how to construct neural estimators most effectively.","category":"page"},{"location":"motivation/#Motivation","page":"Motivation","title":"Motivation","text":"","category":"section"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"Definition of an estimator:","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"hatmathbftheta  mathcalS^m to Theta","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"Permutation invariance:","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"hatmathbftheta(mathbfZ_1 dots mathbfZ_m) = hatmathbftheta(mathbfZ_pi(1) dots mathbfZ_pi(m))","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"Under some arbitrary loss function L(mathbftheta hatmathbftheta(mathcalZ)), the risk function:","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"R(mathbftheta hatmathbftheta(cdot)) equiv int_mathcalS^m  L(mathbftheta hatmathbftheta(mathcalZ))p(mathcalZ mid mathbftheta) d mathcalZ","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"Weighted average risk function:","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"r_Omega(hatmathbftheta(cdot))\nequiv int_Theta R(mathbftheta hatmathbftheta(cdot)) dOmega(mathbftheta)  ","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"Deep Set (Zaheer et al., 2017) representation of an estimator:","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"beginaligned\nhatmathbftheta(mathcalZ) = mathbfphi(mathbfT(mathcalZ)) \nmathbfT(mathcalZ)  = sum_mathbfZ in mathcalZ mathbfpsi(mathbfZ)\nendaligned","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"Optimisation task:","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"hatmathbftheta_mathbfgamma^*(cdot)\nmathbfgamma^*\nequiv\nundersetmathbfgammamathrmargmin  r_Omega(hatmathbftheta_mathbfgamma(cdot))","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"Monte Carlo approximation of the weighted average risk:","category":"page"},{"location":"motivation/","page":"Motivation","title":"Motivation","text":"r_Omega(hatmathbftheta(cdot))\napprox\nfrac1K sum_k = 1^K frac1J sum_j = 1^J L(mathbftheta_k hatmathbftheta(mathcalZ_kj))  ","category":"page"},{"location":"API/core/#Core-functions","page":"Core functions","title":"Core functions","text":"","category":"section"},{"location":"API/core/#Parameters","page":"Core functions","title":"Parameters","text":"","category":"section"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"ParameterConfigurations\n\nsubsetparameters","category":"page"},{"location":"API/core/#NeuralEstimators.ParameterConfigurations","page":"Core functions","title":"NeuralEstimators.ParameterConfigurations","text":"ParameterConfigurations\n\nAn abstract supertype for storing parameters Œ∏ and any intermediate objects needed for data simulation with simulate.\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.subsetparameters","page":"Core functions","title":"NeuralEstimators.subsetparameters","text":"subsetparameters(parameters::Parameters, indices) where {Parameters <: ParameterConfigurations}\n\nSubset parameters using a collection of indices.\n\nThe default method assumes that each field of parameters is an array. If the last dimension of the array has size equal to the number of parameter configurations, K, then the array is subsetted over its last dimension using indices; otherwise, the field is returned unchanged. If this default does not cover your use case, define an appropriate subsetting method by overloading subsetparameters after running import NeuralEstimators: subsetparameters.\n\n\n\n\n\n","category":"function"},{"location":"API/core/#Simulation","page":"Core functions","title":"Simulation","text":"","category":"section"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"simulate","category":"page"},{"location":"API/core/#NeuralEstimators.simulate","page":"Core functions","title":"NeuralEstimators.simulate","text":"simulate(parameters::P, Œæ, m::Integer, num_rep::Integer) where {P <: ParameterConfigurations}\n\nGeneric method that simulates num_rep sets of  sets of m independent replicates for each parameter configuration by calling simulate(parameters, Œæ, m).\n\nSee also Data simulation.\n\n\n\n\n\n","category":"function"},{"location":"API/core/#Deep-Set-representation","page":"Core functions","title":"Deep Set representation","text":"","category":"section"},{"location":"API/core/#Vanilla-Deep-Set","page":"Core functions","title":"Vanilla Deep Set","text":"","category":"section"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"DeepSet\n\nDeepSet(œà, œï; aggregation::String)","category":"page"},{"location":"API/core/#NeuralEstimators.DeepSet","page":"Core functions","title":"NeuralEstimators.DeepSet","text":"DeepSet(œà, œï, agg)\n\nImplementation of the Deep Set framework, where œà and œï are neural networks (e.g., Flux networks) and agg is a symmetric function that pools data over the last dimension (the replicates/batch dimension) of an array.\n\nDeepSet objects are applied to AbstractVectors of AbstractArrays, where each array is associated with one parameter vector.\n\nExamples\n\nn = 10 # observations in each realisation\np = 5  # number of parameters in the statistical model\nw = 32 # width of each layer\nœà = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï = Chain(Dense(w, w, relu), Dense(w, p));\nagg(X) = sum(X, dims = ndims(X))\nŒ∏ÃÇ  = DeepSet(œà, œï, agg)\n\n# A single set of m=3 realisations:\nZ = [rand(n, 1, 3)];\nŒ∏ÃÇ (Z)\n\n# Two sets each containing m=3 realisations:\nZ = [rand(n, 1, m) for m ‚àà (3, 3)];\nŒ∏ÃÇ (Z)\n\n# Two sets respectivaly containing m=3 and m=4 realisations:\nZ = [rand(n, 1, m) for m ‚àà (3, 4)];\nŒ∏ÃÇ (Z)\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.DeepSet-Tuple{Any, Any}","page":"Core functions","title":"NeuralEstimators.DeepSet","text":"DeepSet(œà, œï; aggregation::String = \"mean\")\n\nConvenient constructor for a DeepSet object with agg equal to the \"mean\", \"sum\", or \"logsumexp\" function.\n\n\n\n\n\n","category":"method"},{"location":"API/core/#Deep-Set-with-expert-summary-statistics","page":"Core functions","title":"Deep Set with expert summary statistics","text":"","category":"section"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"DeepSetExpert\n\nDeepSetExpert(deepset::DeepSet, œï, S)\n\nDeepSetExpert(œà, œï, S; aggregation::String)\n\nsamplesize","category":"page"},{"location":"API/core/#NeuralEstimators.DeepSetExpert","page":"Core functions","title":"NeuralEstimators.DeepSetExpert","text":"DeepSetExpert(œà, œï, S, agg)\n\nImplementation of the Deep Set framework with œà and œï neural networks, agg a symmetric function that pools data over the last dimension of an array, and S a vector of real-valued functions that serve as expert summary statistics.\n\nThe dimension of the domain of œï should be q‚Çú + q‚Çõ, where q‚Çú is the range of œï and q‚Çõ is the dimension of S, that is, length(S). DeepSetExpert objects are applied to AbstractVectors of AbstractArrays, where each array is associated with one parameter vector. The functions œà and S both act on these arrays individually (i.e., they are broadcasted over the AbstractVector).\n\n\n\n\n\n","category":"type"},{"location":"API/core/#NeuralEstimators.DeepSetExpert-Tuple{DeepSet, Any, Any}","page":"Core functions","title":"NeuralEstimators.DeepSetExpert","text":"DeepSetExpert(deepset::DeepSet, œï, S)\n\nDeepSetExpert constructor with the aggregation function agg and inner neural network œà inherited from deepset.\n\nNote that we cannot inherit the outer network, œï, since DeepSetExpert objects require the dimension of the domain of œï to be q‚Çú + q‚Çõ.\n\n\n\n\n\n","category":"method"},{"location":"API/core/#NeuralEstimators.DeepSetExpert-Tuple{Any, Any, Any}","page":"Core functions","title":"NeuralEstimators.DeepSetExpert","text":"DeepSetExpert(œà, œï, S; aggregation::String = \"mean\")\n\nDeepSetExpert constructor with agg equal to the \"mean\", \"sum\", or \"logsumexp\" function.\n\n\n\n\n\n","category":"method"},{"location":"API/core/#NeuralEstimators.samplesize","page":"Core functions","title":"NeuralEstimators.samplesize","text":"samplesize(x::A) where {A <: AbstractArray{T, N}} where {T, N}\n\nComputes the sample size m for a set of independent realisations Z, useful as an expert summary statistic in DeepSetExpert objects.\n\n\n\n\n\n","category":"function"},{"location":"API/core/#Piecewise-Deep-Set-neural-estimators","page":"Core functions","title":"Piecewise Deep Set neural estimators","text":"","category":"section"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"DeepSetPiecewise","category":"page"},{"location":"API/core/#NeuralEstimators.DeepSetPiecewise","page":"Core functions","title":"NeuralEstimators.DeepSetPiecewise","text":"DeepSetPiecewise(estimators, m_cutoffs)\n\nGiven an arbitrary number of estimators, creates a piecewise neural estimator based on the sample size cut offs, m_cutoffs, which should contain one element fewer than the number of estimators.\n\nExamples\n\nSuppose that we have two neural estimators, Œ∏ÃÇ‚ÇÅ and Œ∏ÃÇ‚ÇÇ, taking the following arbitrary forms:\n\nn = 10\np = 5\nw = 32\n\nœà‚ÇÅ = Chain(Dense(n, w, relu), Dense(w, w, relu));\nœï‚ÇÅ = Chain(Dense(w, w, relu), Dense(w, p));\nŒ∏ÃÇ‚ÇÅ = DeepSet(œà‚ÇÅ, œï‚ÇÅ)\n\nœà‚ÇÇ = Chain(Dense(n, w, relu), Dense(w, w, relu), Dense(w, w, relu));\nœï‚ÇÇ = Chain(Dense(w, w, relu), Dense(w, w, relu), Dense(w, p));\nŒ∏ÃÇ‚ÇÇ = DeepSet(œà‚ÇÇ, œï‚ÇÇ)\n\nFurther suppose that we've trained Œ∏ÃÇ‚ÇÅ for small sample sizes (e.g., m ‚â§ 30) and Œ∏ÃÇ‚ÇÇ for moderate-to-large sample sizes (e.g., m > 30). Then we construct a piecewise Deep Set object with a cut-off sample size of 30 which dispatches Œ∏ÃÇ‚ÇÅ if m ‚â§ 30 and Œ∏ÃÇ‚ÇÇ if m > 30:\n\nŒ∏ÃÇ = DeepSetPiecewise((Œ∏ÃÇ‚ÇÅ, Œ∏ÃÇ‚ÇÇ), (30,))\nZ = [rand(Float32, n, 1, m) for m ‚àà (10, 50)]\nŒ∏ÃÇ(Z)\n\n\n\n\n\n","category":"type"},{"location":"API/core/#Training","page":"Core functions","title":"Training","text":"","category":"section"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"There are two training methods. For both methods, the validation parameters and validation data are held fixed so that the validation risk is interpretable. There are a number of practical considerations to keep in mind: In particular, see Balancing time and memory complexity during training.","category":"page"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"train","category":"page"},{"location":"API/core/#NeuralEstimators.train","page":"Core functions","title":"NeuralEstimators.train","text":"train(Œ∏ÃÇ, Œæ, P; <keyword args>) where {P <: ParameterConfigurations}\n\nTrain the neural estimator Œ∏ÃÇ by providing the invariant model information Œæ needed for the constructor P to automatically sample the sets of training and validation parameters.\n\nKeyword arguments common to both train methods:\n\nm: sample sizes (either an Integer or a collection of Integers).\nbatchsize::Integer = 32\nepochs::Integer = 100: the maximum number of epochs used during training.\nepochs_per_Z_refresh::Integer = 1: how often to refresh the training data.\nloss = mae: the loss function, which should return an average loss when applied to multiple replicates.\noptimiser = ADAM(1e-4)\nsavepath::String = \"runs/\": path to save the trained Œ∏ÃÇ and other information; if savepath is an empty string (i.e., \"\"), nothing is saved.\nsimulate_just_in_time::Bool = false: should we do \"just-in-time\" data simulation, which improves memory complexity at the cost of time complexity?\nstopping_epochs::Integer = 10: cease training if the risk doesn't improve in stopping_epochs epochs.\nuse_gpu::Bool = true\nverbose::Bool = true\n\nSimulator keyword arguments only:\n\nK::Integer = 10_000: the number of parameters in the training set; the size of the validation set is K √∑ 5.\nepochs_per_Œ∏_refresh::Integer = 1: how often to refresh the training parameters; this must be a multiple of epochs_per_Z_refresh.\n\n\n\n\n\ntrain(Œ∏ÃÇ, Œæ, Œ∏_train::P, Œ∏_val::P; <keyword args>) where {P <: ParameterConfigurations}\n\nTrain the neural estimator Œ∏ÃÇ by providing the training and validation sets explicitly as Œ∏_train and Œ∏_val, which are both held fixed during training, as well as the invariant model information Œæ.\n\n\n\n\n\n","category":"function"},{"location":"API/core/#Estimation","page":"Core functions","title":"Estimation","text":"","category":"section"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"estimate\n\nEstimates\n\nmerge(::Estimates)","category":"page"},{"location":"API/core/#NeuralEstimators.estimate","page":"Core functions","title":"NeuralEstimators.estimate","text":"estimate(estimators, Œæ, parameters::P; <keyword args>) where {P <: ParameterConfigurations}\n\nUsing a collection of estimators, compute estimates from data simulated from a set of parameters with invariant information Œæ.\n\nNote that estimate() requires the user to have defined a method simulate(parameters, Œæ, m::Integer).\n\nKeyword arguments\n\nm::Vector{Integer}: sample sizes to estimate from.\nestimator_names::Vector{String}: names of the estimators (sensible default values provided).\nparameter_names::Vector{String}: names of the parameters (sensible default values provided).\nnum_rep::Integer = 1: the number of times to replicate each parameter in parameters.\nsave::Vector{String}: by default, no objects are saved; however, if save is provided, four DataFrames respectively containing the true parameters Œ∏, estimates Œ∏ÃÇ, runtimes, and merged Œ∏ and Œ∏ÃÇ will be saved in the directory save[1] with file names (not extensions) suffixed by save[2].\nuse_Œæ = false: a Bool or a collection of Bool objects with length equal to the number of estimators. Specifies whether or not the estimator uses the invariant model information, Œæ: If it does, the estimator will be applied as estimator(Z, Œæ).\nuse_gpu = true: a Bool or a collection of Bool objects with length equal to the number of estimators.\nverbose::Bool = true\n\n\n\n\n\n","category":"function"},{"location":"API/core/#NeuralEstimators.Estimates","page":"Core functions","title":"NeuralEstimators.Estimates","text":"Estimates(Œ∏, Œ∏ÃÇ, runtime)\n\nA set of true parameters Œ∏, corresponding estimates Œ∏ÃÇ, and the runtime to obtain Œ∏ÃÇ, as returned by a call to estimate.\n\n\n\n\n\n","category":"type"},{"location":"API/core/#Base.merge-Tuple{Estimates}","page":"Core functions","title":"Base.merge","text":"merge(estimates::Estimates)\n\nMerge estimates into a single long-form DataFrame containing the true parameters and the corresponding estimates.\n\n\n\n\n\n","category":"method"},{"location":"API/core/#Bootstrapping","page":"Core functions","title":"Bootstrapping","text":"","category":"section"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"Note that all bootstrapping functions are currently implemented for a single parameter configuration only.","category":"page"},{"location":"API/core/","page":"Core functions","title":"Core functions","text":"parametricbootstrap\n\nnonparametricbootstrap","category":"page"},{"location":"API/core/#NeuralEstimators.parametricbootstrap","page":"Core functions","title":"NeuralEstimators.parametricbootstrap","text":"parametricbootstrap(Œ∏ÃÇ, parameters::P, Œæ, m::Integer; B::Integer = 100, use_gpu::Bool = true) where {P <: ParameterConfigurations}\n\nReturns B parameteric bootstrap samples of an estimator Œ∏ÃÇ as a p √ó B matrix, where p is the number of parameters in the statistical model, based on data sets of size m simulated using the invariant model information Œæ and parameter configurations, parameters.\n\nThis function requires the user to have defined a method simulate(parameters::P, Œæ, m::Integer).\n\n\n\n\n\n","category":"function"},{"location":"API/core/#NeuralEstimators.nonparametricbootstrap","page":"Core functions","title":"NeuralEstimators.nonparametricbootstrap","text":"nonparametricbootstrap(Œ∏ÃÇ, Z::AbstractArray{T, N}; B::Integer = 100, use_gpu::Bool = true)\nnonparametricbootstrap(Œ∏ÃÇ, Z::AbstractArray{T, N}, blocks; B::Integer = 100, use_gpu::Bool = true)\n\nReturns B non-parametric bootstrap samples of an estimator Œ∏ÃÇ as a p √ó B matrix, where p is the number of parameters in the statistical model.\n\nThe argument blocks caters for block bootstrapping, and should be an integer vector specifying the block for each replicate. For example, if we have 5 replicates with the first two replicates corresponding to block 1 and the remaining replicates corresponding to block 2, then blocks should be [1, 1, 2, 2, 2]. The resampling algorithm tries to produce resampled data sets of a similar size to the original data, but this can only be achieved exactly if the blocks are the same length.\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#Utility-functions","page":"Utility functions","title":"Utility functions","text":"","category":"section"},{"location":"API/utility/","page":"Utility functions","title":"Utility functions","text":"loadbestweights\n\nstackarrays\n\nexpandgrid","category":"page"},{"location":"API/utility/#NeuralEstimators.loadbestweights","page":"Utility functions","title":"NeuralEstimators.loadbestweights","text":"loadbestweights(path::String)\n\nGiven a path to a training run containing neural networks saved with names 'networkepochx.bson' and an object saved as 'lossper_epoch.bson',  returns the weights of the best network (measured by validation loss).\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.stackarrays","page":"Utility functions","title":"NeuralEstimators.stackarrays","text":"stackarrays(v::V; merge::Bool = true) where {V <: AbstractVector{A}} where {A <: AbstractArray{T, N}} where {T, N}\n\nStack a vector of arrays v along the last dimension of each array, optionally merging the final dimension of the stacked array.\n\nThe arrays must be of the same for the first N-1 dimensions. However, if merge = true, the size of the final dimension can vary between arrays.\n\nExamples\n\n# Vector containing arrays of the same size:\nZ = [rand(2, 3, m) for m ‚àà (1, 1)];\nstackarrays(Z)\nstackarrays(Z, merge = false)\n\n# Vector containing arrays with differing final dimension size:\nZ = [rand(2, 3, m) for m ‚àà (1, 2)];\nstackarrays(Z)\n\n\n\n\n\n","category":"function"},{"location":"API/utility/#NeuralEstimators.expandgrid","page":"Utility functions","title":"NeuralEstimators.expandgrid","text":"expandgrid(xs, ys)\n\nSame as expand.grid() in R, but currently caters for two dimensions only.\n\n\n\n\n\n","category":"function"},{"location":"workflow/simpleexample/#Simple-example","page":"Simple example","title":"Simple example","text":"","category":"section"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"Here, we consider a very simple estimation task, namely, inferring mu from N(mu sigma) data, where sigma is known. Specifically, we will develop a neural estimator for Œº, where","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"mu sim N(0 05) quad mathcalZ equiv Z_1 dots Z_m  Z_i sim N(Œº 1)","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"The first step is to define an object Œæ that contains invariant model information. In this example, we have two invariant objects: The prior distribution of the parameters, Œ©, and the standard deviation, œÉ.","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"using Distributions\nŒæ = (Œ© = Normal(0, 0.5), œÉ = 1)","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"Next, we define a subtype of ParameterConfigurations which, for the current model, stores the sampled parameters only:","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"using NeuralEstimators\nstruct Parameters <: ParameterConfigurations\n\tŒ∏\nend","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"We then define a Parameters constructor, returning K draws from Œ©:","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"function Parameters(Œæ, K::Integer)\n\tŒ∏ = rand(Œæ.Œ©, 1, K)\n\tParameters(Œ∏)\nend","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"Next, we implicitly define the statistical model by overloading simulate as follows.","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"import NeuralEstimators: simulate\nfunction simulate(parameters::Parameters, Œæ, m::Integer)\n\tŒ∏ = vec(parameters.Œ∏)\n\tZ = [rand(Normal(Œº, Œæ.œÉ), 1, 1, m) for Œº ‚àà Œ∏]\nend","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"There is some flexibility in the permitted type of the sample size m (e.g., Integer, IntegerRange, etc.), but simulate must return an AbstractVector of (multi-dimensional) AbstractArrays, where each array is associated with one parameter vector (i.e., one column of parameters.Œ∏). Note also that the size of each array must be amenable to Flux neural networks; for instance, above we return a 3-dimensional array, even though the second dimension is redundant.","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"We then choose an architecture for modelling œà(‚ãÖ) and œï(‚ãÖ) in the Deep Set framework, and initialise the neural estimator as a DeepSet object.","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"p = 1\nw = 32\nq = 16\nœà = Chain(Dense(n, w, relu), Dense(w, q, relu))\nœï = Chain(Dense(q, w, relu), Dense(w, p), flatten)\nŒ∏ÃÇ = DeepSet(œà, œï)","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"Next, we train the neural estimator using train, which has two methods: Below, we provide the invariant model information Œæ and the type Parameters, so that parameter configurations will be automatically and continuously sampled during training. The argument m specifies the sample size used during training, and its type should be consistent with the simulate method defined above.","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"Œ∏ÃÇ = train(Œ∏ÃÇ, Œæ, Parameters, m = 10)","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"The estimator Œ∏ÃÇ now approximates the Bayes estimator. It's usually a good idea to assess the performance of the estimator before putting it into practice. Since the performance of Œ∏ÃÇ for particular values of Œ∏ may be of particular interest, estimate takes an instance of Parameters.","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"parameters = Parameters(Œæ, 500)                   # test set with 500 parameters\nm          = [1, 10, 30]                          # sample sizes we wish to test\nestimates  = estimate(Œ∏ÃÇ, Œæ, parameters, m = m)  ","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"The true parameters, estimates, and timings from this test run are returned in an Estimates object (each field is a DataFrame corresponding to the parameters, estimates, or timings). The true parameters and estimates may be merged into a convenient long-form DataFrame, and this greatly facilitates visualisation and diagnostic computation:","category":"page"},{"location":"workflow/simpleexample/","page":"Simple example","title":"Simple example","text":"merged_df = merge(estimates)","category":"page"},{"location":"#NeuralEstimators","page":"Home","title":"NeuralEstimators","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Neural estimators are a recent approach to likelihood-free inference, and have emerged as a promising alternative to the well-establish approximate Bayesian computation (ABC). NeuralEstimators aims to faciliate the development of neural estimators in a user-friendly manner. In particular, it aims to alleviate the user from the substantial amount of boilerplate code needed to implement neural estimators from scratch. To this end, the main task asked of the user is to implicitly define the statistical model by providing a function for simulating data; everything else is handled by NeuralEstimators.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Julia has many attractive features; in particular, it has been designed to alleviate the so-called two-language problem, whereby it aims to be both easy to develop and fast in its execution. This means that users can easily write code for data simulation without needing to vectorise (i.e., for loops are fine!). Further, many Julia packages are written entirely in Julia and, hence, their source code is easily understood and extended; this includes NeuralEstimators and, importantly, the deep learning framework on which it is built upon, Flux.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Download Julia if you haven't already. To install NeuralEstimators from Julia's package manager, use the following commands inside the Julia REPL:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"NeuralEstimators\")","category":"page"},{"location":"#Getting-started","page":"Home","title":"Getting started","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See our Workflow overview.","category":"page"},{"location":"#Supporting-and-citing","page":"Home","title":"Supporting and citing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This software was developed as part of academic research. If you would like to help support it, please star the repository. If you use NeuralEstimators in your research or other activities, please use the following citation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"@article{\n  <bibtex citation>\n}","category":"page"}]
}
